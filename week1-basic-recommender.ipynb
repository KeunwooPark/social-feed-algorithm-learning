{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc4432b",
   "metadata": {},
   "source": [
    "# Basic Movie Recommender\n",
    "\n",
    "This notebook uses Chapter 9 contents of Mining of Massive Datasets to implement mini movie recommendation system. \n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "Download the MovieLens 100k dataset and unzip under `data` folder.\n",
    "\n",
    "## Goal\n",
    "\n",
    "* Implement user-user collaborative filtering and item-item collaborative filtering, and compare them.\n",
    "* Calculate metrics: Precision@10, Recall@10, NDCG\n",
    "* Using 5-fold cross validation while developing the model.\n",
    "* Use `ua` and `ub` data for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "081756be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install necessary packages\n",
    "%pip install pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e7c7118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0        1        1       5  874965758\n",
      "1        1        2       3  876893171\n",
      "2        1        3       4  878542960\n",
      "3        1        4       3  876893119\n",
      "4        1        5       3  889751712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_rating_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    return df\n",
    "\n",
    "def load_user_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='|', names=['user_id', 'age', 'gender', 'occupation', 'zip_code'])\n",
    "    return df\n",
    "\n",
    "def load_item_data(file_path):\n",
    "    df = pd.read_csv(file_path, sep='|', encoding='latin-1', names=[\n",
    "        'item_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "        'unknown', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy',\n",
    "        'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "        'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "user_df = load_user_data('./data/ml-100k/u.user')\n",
    "item_df = load_item_data('./data/ml-100k/u.item')\n",
    "\n",
    "rating_file = './data/ml-100k/u1.base'\n",
    "rating_df = load_rating_data(rating_file)\n",
    "\n",
    "print(rating_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f7d76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "class UserColaborativeFiltering:\n",
    "    def __init__(self, rating_df):\n",
    "        self.user_item_matrix = self.create_user_item_matrix(rating_df)\n",
    "        self.similarity_matrix = self.user_user_similarity_matrix(self.user_item_matrix)\n",
    "\n",
    "    def normalize_ratings(self, user_item_matrix, mean_user_rating):\n",
    "        normalized_matrix = user_item_matrix.subtract(mean_user_rating, axis=0)\n",
    "        return normalized_matrix\n",
    "    \n",
    "    def create_user_item_matrix(self, rating_df):\n",
    "        user_item_matrix = rating_df.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "        return user_item_matrix\n",
    "\n",
    "    def user_user_similarity_matrix(self, user_item_matrix):\n",
    "        similarity_matrix = cosine_similarity(user_item_matrix)\n",
    "        similarity_df = pd.DataFrame(similarity_matrix, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "        return similarity_df\n",
    "\n",
    "    def predict_rating(self, X):\n",
    "        \"\"\"\n",
    "            X: DataFrame with columns ['user_id', 'item_id']\n",
    "            return predicted ratings for the given user-item pairs\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            item_id = row['item_id']\n",
    "\n",
    "            if item_id not in self.user_item_matrix.columns:\n",
    "                predictions.append(0)\n",
    "                continue\n",
    "\n",
    "            user_similarities = self.similarity_matrix[user_id]\n",
    "            k = 30\n",
    "            top_k_similar = user_similarities.nlargest(k+1).iloc[1:]\n",
    "            ratings_of_top_k_users = self.user_item_matrix.loc[top_k_similar.index, item_id]\n",
    "            non_zero_mean = ratings_of_top_k_users[ratings_of_top_k_users != 0].mean()\n",
    "            if np.isnan(non_zero_mean):\n",
    "                non_zero_mean = 0\n",
    "\n",
    "            # need to round because the ratings are integers\n",
    "            non_zero_mean = round(non_zero_mean, 0)\n",
    "            predictions.append(non_zero_mean)\n",
    "\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9a83b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test samples: 2.32379000772445\n"
     ]
    }
   ],
   "source": [
    "ucf = UserColaborativeFiltering(rating_df)\n",
    "\n",
    "test_rating_file = './data/ml-100k/u1.test'\n",
    "test_rating_df = load_rating_data(test_rating_file)\n",
    "test_samples = test_rating_df[['user_id', 'item_id']].head(5)\n",
    "\n",
    "def evaluate_rmse(true_ratings, predicted_ratings):\n",
    "    true_ratings = np.array(true_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "    mse = np.mean((true_ratings - predicted_ratings) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "predictions = ucf.predict_rating(test_samples)\n",
    "rmse = evaluate_rmse(test_rating_df['rating'].head(5), predictions)\n",
    "print(f'RMSE on test samples: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99a819ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemColaborativeFiltering:\n",
    "    def __init__(self, rating_df):\n",
    "        self.user_item_matrix = self.create_user_item_matrix(rating_df)\n",
    "        self.similarity_matrix = self.item_item_similarity_matrix(self.user_item_matrix)\n",
    "\n",
    "    def create_user_item_matrix(self, rating_df):\n",
    "        user_item_matrix = rating_df.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "        return user_item_matrix\n",
    "\n",
    "    def item_item_similarity_matrix(self, user_item_matrix):\n",
    "        similarity_matrix = cosine_similarity(user_item_matrix.T)\n",
    "        similarity_df = pd.DataFrame(similarity_matrix, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n",
    "        return similarity_df\n",
    "\n",
    "    def predict_rating(self, X):\n",
    "        \"\"\"\n",
    "            X: DataFrame with columns ['user_id', 'item_id']\n",
    "            return predicted ratings for the given user-item pairs\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "        for _, row in X.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            item_id = row['item_id']\n",
    "\n",
    "            if item_id not in self.user_item_matrix.columns:\n",
    "                predictions.append(0)\n",
    "                continue\n",
    "\n",
    "            item_similarities = self.similarity_matrix[item_id]\n",
    "            k = 30\n",
    "            top_k_similar = item_similarities.nlargest(k+1).iloc[1:]\n",
    "            ratings_of_top_k_items = self.user_item_matrix.loc[user_id, top_k_similar.index]\n",
    "            non_zero_mean = ratings_of_top_k_items[ratings_of_top_k_items != 0].mean()\n",
    "            if np.isnan(non_zero_mean):\n",
    "                non_zero_mean = 0\n",
    "\n",
    "            # need to round because the ratings are integers\n",
    "            non_zero_mean = round(non_zero_mean, 0)\n",
    "            predictions.append(non_zero_mean)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54325be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test samples: 0.6324555320336759\n"
     ]
    }
   ],
   "source": [
    "icf = ItemColaborativeFiltering(rating_df)\n",
    "predictions = icf.predict_rating(test_samples)\n",
    "rmse = evaluate_rmse(test_rating_df['rating'].head(5), predictions)\n",
    "print(f'RMSE on test samples: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0c3e9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserCF RMSE on A test: 1.25231492961109\n",
      "ItemCF RMSE on A test: 1.2804509412458698\n",
      "UserCF performs better on A test\n",
      "UserCF RMSE on B test: 1.2442444376297772\n",
      "ItemCF RMSE on B test: 1.275721574453031\n",
      "UserCF performs better on B test\n"
     ]
    }
   ],
   "source": [
    "def validate(train_file, test_file, model_class):\n",
    "    train_rating_df = load_rating_data(train_file)\n",
    "    model = model_class(train_rating_df)\n",
    "    test_rating_df = load_rating_data(test_file)\n",
    "    test_samples = test_rating_df[['user_id', 'item_id']]\n",
    "    predictions = model.predict_rating(test_samples)\n",
    "    rmse = evaluate_rmse(test_rating_df['rating'], predictions)\n",
    "    return rmse\n",
    "    \n",
    "\n",
    "# run A test\n",
    "train_file = './data/ml-100k/ua.base'\n",
    "test_file = './data/ml-100k/ua.test'\n",
    "rmse_ucf = validate(train_file, test_file, UserColaborativeFiltering)\n",
    "rmse_icf = validate(train_file, test_file, ItemColaborativeFiltering)\n",
    "print(f'UserCF RMSE on A test: {rmse_ucf}')\n",
    "print(f'ItemCF RMSE on A test: {rmse_icf}')\n",
    "\n",
    "if (rmse_ucf < rmse_icf):\n",
    "    print(\"UserCF performs better on A test\")\n",
    "else:\n",
    "    print(\"ItemCF performs better on A test\")\n",
    "\n",
    "# run B test\n",
    "train_file = './data/ml-100k/ub.base'\n",
    "test_file = './data/ml-100k/ub.test'\n",
    "rmse_ucf = validate(train_file, test_file, UserColaborativeFiltering)\n",
    "rmse_icf = validate(train_file, test_file, ItemColaborativeFiltering)\n",
    "print(f'UserCF RMSE on B test: {rmse_ucf}')\n",
    "print(f'ItemCF RMSE on B test: {rmse_icf}')\n",
    "if (rmse_ucf < rmse_icf):\n",
    "    print(\"UserCF performs better on B test\")\n",
    "else:\n",
    "    print(\"ItemCF performs better on B test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
